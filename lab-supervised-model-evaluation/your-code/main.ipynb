{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:07.851779Z",
     "start_time": "2020-05-13T15:29:06.655458Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the boston dataset using sklearn and get the datasets X and y containing the target and the rest of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:08.842344Z",
     "start_time": "2020-05-13T15:29:07.854811Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:08.859178Z",
     "start_time": "2020-05-13T15:29:08.845769Z"
    }
   },
   "outputs": [],
   "source": [
    "boston_full = pd.DataFrame(data=boston.data, columns=boston.feature_names)\n",
    "boston_full['MEDV'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:08.906168Z",
     "start_time": "2020-05-13T15:29:08.868158Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:08.970491Z",
     "start_time": "2020-05-13T15:29:08.909412Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LinReg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = LinReg.predict(X_test)\n",
    "\n",
    "y_train_pred = LinReg.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:08.983249Z",
     "start_time": "2020-05-13T15:29:08.974246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Train: 0.762\n",
      "R2 Test: 0.530\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_test_pred_r2 = r2_score(y_test, y_test_pred)\n",
    "y_train_pred_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(f'R2 Train: {y_train_pred_r2:.3f}\\nR2 Test: {y_test_pred_r2:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:09.031177Z",
     "start_time": "2020-05-13T15:29:08.986436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Train: 0.7624075606911873\n",
      "R2 Test: 0.5300888977311797\n"
     ]
    }
   ],
   "source": [
    "print(f'R2 Train: {np.mean(y_train_pred_r2)}\\nR2 Test: {np.mean(y_test_pred_r2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-06T11:04:12.134381Z",
     "start_time": "2019-10-06T11:04:12.130110Z"
    }
   },
   "source": [
    "Load the iris dataset using sklearn and get the datasets X and y containing the target and the rest of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:09.056395Z",
     "start_time": "2020-05-13T15:29:09.043213Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:09.080830Z",
     "start_time": "2020-05-13T15:29:09.070916Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:09.143999Z",
     "start_time": "2020-05-13T15:29:09.084553Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogR = LogisticRegression(random_state=0).fit(X, y)\n",
    "\n",
    "y_test_pred = LogR.predict(X_test)\n",
    "y_train_pred = LogR.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:09.154147Z",
     "start_time": "2020-05-13T15:29:09.147292Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics\\\n",
    "import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:09.167399Z",
     "start_time": "2020-05-13T15:29:09.157331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 116\n",
      "Test accuracy: 30\n"
     ]
    }
   ],
   "source": [
    "print(f'Train accuracy: {accuracy_score(y_train, y_train_pred, normalize=False)}\\n'\n",
    "      f'Test accuracy: {accuracy_score(y_test, y_test_pred, normalize=False)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:09.194917Z",
     "start_time": "2020-05-13T15:29:09.170344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train balanced accuracy: 0.9671\n",
      "Test balanced accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(f'Train balanced accuracy: {balanced_accuracy_score(y_train, y_train_pred):.4f}\\n'\n",
    "      f'Test balanced accuracy: {balanced_accuracy_score(y_test, y_test_pred):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:09.214553Z",
     "start_time": "2020-05-13T15:29:09.203245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train precision: 0.9675\n",
      "Test precision: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(f'Train precision: {precision_score(y_train, y_train_pred, average=\"weighted\"):.4f}\\n'\n",
    "      f'Test precision: {precision_score(y_test, y_test_pred, average=\"weighted\"):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:09.242077Z",
     "start_time": "2020-05-13T15:29:09.225784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train recall: 0.9667\n",
      "Test recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(f'Train recall: {recall_score(y_train, y_train_pred, average=\"weighted\"):.4f}\\n'\n",
    "      f'Test recall: {recall_score(y_test, y_test_pred, average=\"weighted\"):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:09.266147Z",
     "start_time": "2020-05-13T15:29:09.247983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9667\n",
      "Test F1: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(f'Train F1: {f1_score(y_train, y_train_pred, average=\"weighted\"):.4f}\\n'\n",
    "      f'Test F1: {f1_score(y_test, y_test_pred, average=\"weighted\"):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:09.295084Z",
     "start_time": "2020-05-13T15:29:09.268840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  0,  0],\n",
       "       [ 0, 38,  3],\n",
       "       [ 0,  1, 38]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T15:29:09.314143Z",
     "start_time": "2020-05-13T15:29:09.300167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Confusion Matrix\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(f'Test Confusion Matrix\\n{confusion_matrix(y_test, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: For each of the data sets in this lab, try training with some of the other models you have learned about, recalculate the evaluation metrics, and compare to determine which models perform best on each data set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
